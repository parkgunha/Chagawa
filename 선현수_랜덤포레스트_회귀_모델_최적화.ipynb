{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcy9AOJhpJQwr9Ph8EIqFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkgunha/Chagawa_project/blob/main/%EC%84%A0%ED%98%84%EC%88%98_%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8_%ED%9A%8C%EA%B7%80_%EB%AA%A8%EB%8D%B8_%EC%B5%9C%EC%A0%81%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjbqD8pv20cT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/full_2_data.csv'\n",
        "full2_data =  pd.read_csv(file_path)\n",
        "full2_data"
      ],
      "metadata": {
        "id": "w4j1Ubt122qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#인코딩\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "\n",
        "def Encoding(df, lable_list, onhot_list):\n",
        "  \"\"\" 범주형데이터를 숫자형으로 변경하는 함수\n",
        "  df: 변경할 데이터 프레임\n",
        "  lable_list: 라벨 인코딩\n",
        "  onhot_list: 원핫 인코딩\n",
        "  \"\"\"\n",
        "  # 라벨 인코딩\n",
        "  encoding_df=df.copy()\n",
        "  le = LabelEncoder()\n",
        "  encoding_df[lable_list] = encoding_df[lable_list].apply(le.fit_transform)\n",
        "  # 원 핫 인코딩\n",
        "  encoding_df = pd.get_dummies(encoding_df, columns=onhot_list, drop_first= True, dtype=float)\n",
        "  # drop_first: 첫번째 더미 삭제, dtype: 불리언에서 정수형으로변경\n",
        "  print(len(encoding_df.columns))\n",
        "  return encoding_df\n",
        "\n",
        "#데이터 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "def Data_split(df, price):\n",
        "  \"\"\" 데이터를 분할하는 함수\n",
        "  df: 분할할 데이터 프레임\n",
        "  price: 종속 변수명\n",
        "  출력\n",
        "  X_train: 학습데이터\n",
        "  X_test: 테스트 데이터\n",
        "  y_train: 학습데이터(실제값)\n",
        "  y_test: 테스트데이터(실제값)\n",
        "  \"\"\"\n",
        "  X = df.drop(columns=price)\n",
        "  y = df[price]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "  print(X_train.shape, X_test.shape)\n",
        "  print(y_train.shape, y_test.shape)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "from mmap import mmap\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "# 로그 변환\n",
        "def Log_Trans(y_train, y_test):\n",
        "  # y값 로그변환\n",
        "  log_y_train = np.log1p(y_train)\n",
        "  log_y_test = np.log1p(y_test)\n",
        "  return log_y_train, log_y_test\n",
        "\n",
        "# sd 스케일링\n",
        "def Sd_Scaling(X_train, X_test, normalize_columns):\n",
        "  #독립 변수 표준화(standscaler방법)\n",
        "  sd_X_train = X_train.copy()\n",
        "  sd_X_test = X_test.copy()\n",
        "  standscaler = StandardScaler()\n",
        "  #train데이터 스케일링\n",
        "  sd_X_test = X_test.copy()\n",
        "  sd_X_train[normalize_columns] = standscaler.fit_transform(sd_X_train[normalize_columns])\n",
        "  #test데이터 스케일링\n",
        "  sd_X_test[normalize_columns] = standscaler.transform(sd_X_test[normalize_columns])\n",
        "  return sd_X_train, sd_X_test\n",
        "\n",
        "def MinMax_Scaling(X_train, X_test, normalize_columns):\n",
        "  #독립 변수 표준화(standscaler방법)\n",
        "  mm_X_train = X_train.copy()\n",
        "  mm_X_test = X_test.copy()\n",
        "  minmaxscaler = MinMaxScaler()\n",
        "  minmaxscaler.fit(X_train[normalize_columns])\n",
        "  #train데이터 스케일링\n",
        "  mm_X_train[normalize_columns] = minmaxscaler.transform(mm_X_train[normalize_columns])\n",
        "  #test데이터 스케일링\n",
        "  mm_X_test[normalize_columns] = minmaxscaler.transform(mm_X_test[normalize_columns])\n",
        "  return mm_X_train, mm_X_test\n",
        "\n",
        "#  표준 정규화\n",
        "def Robust_Scaling(X_train, X_test, normalize_columns):\n",
        "  #독립 변수 표준 정규화(RobustScaler방법)\n",
        "  robust_X_train = X_train.copy()\n",
        "  robust_X_test = X_test.copy()\n",
        "  robustScaler = RobustScaler()\n",
        "  #train데이터 스케일링\n",
        "  robust_X_train[normalize_columns] = robustScaler.fit_transform(robust_X_train[normalize_columns])\n",
        "  #test데이터 스케일링\n",
        "  robust_X_test[normalize_columns] = robustScaler.transform(robust_X_test[normalize_columns])\n",
        "  return robust_X_train, robust_X_test\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def Rfr_model(x1, x2, y1, y2):\n",
        "  # 랜덤 포레스트 회귀 모델 학습\n",
        "  X_train = x1 # X_train: 학습데이터\n",
        "  X_test = x2 # X_test: 테스트 데이터\n",
        "  y_train = y1 # y_train: 학습데이터(실제값)\n",
        "  y_test = y2 # y_test: 테스트데이터(실제값)\n",
        "  \"\"\"\n",
        "  출력\n",
        "  rfr: 랜덤 포레스트 회귀 모델\n",
        "  y_train_pred: 학습데이터 예측값\n",
        "  y_test_pred: 테스트데이터 예측값\n",
        "  \"\"\"\n",
        "  # 랜덤 포레스트 회귀 모델 학습\n",
        "  rfr = RandomForestRegressor(random_state=42)\n",
        "  rfr.fit(X_train, y_train)\n",
        "  # Fitting된 모델로 예측 수행\n",
        "  y_train_pred = rfr.predict(X_train)\n",
        "  y_test_pred = rfr.predict(X_test)\n",
        "  # 랜덤 포레스트 R2-score\n",
        "  # 학습 정확도\n",
        "  train_accuarcy = rfr.score(X_train, y_train)\n",
        "  print(\"학습 정확도:\",rfr.score(X_train, y_train))\n",
        "  return rfr, y_train_pred, y_test_pred, train_accuarcy\n",
        "\n",
        "def rfr_feature_importances(rfr, X_train):\n",
        "  feature_names = X_train.columns\n",
        "  importance_df = pd.DataFrame({\n",
        "      'Feature': feature_names,\n",
        "      'Importance': rfr.feature_importances_\n",
        "  }).sort_values(by='Importance', ascending=False)\n",
        "  print(importance_df.head())\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "\n",
        "# 역변한 필요한 경우\n",
        "def Exp_y(log_y_test, log_y_test_pred):\n",
        "  trans_y_test = np.expm1(log_y_test) # 실제값\n",
        "  trans_y_test_pred = np.expm1(log_y_test_pred) #예상값\n",
        "  return trans_y_test, trans_y_test_pred\n",
        "\n",
        "def model_evaluation(y_test, y_test_pred, result_name ) :\n",
        "  \"\"\" 모델 평가 함수\n",
        "  trans_y_test: 데스트 데이터 역변환 실제값\n",
        "  trans_y_test_pred: 데스트데이터 역변환 예측값\n",
        "  result_name: 결과를 저장할 컬럼 이름\n",
        "  \"\"\"\n",
        "  mse = round(mean_squared_error(y_test, y_test_pred),3) # 실제 y값, 예측값\n",
        "  mae = round(mean_absolute_error(y_test, y_test_pred),3)\n",
        "  rmse = round(np.sqrt(mean_squared_error(y_test, y_test_pred)),3) # 실제 y값, 예측값\n",
        "  r2 = round(r2_score(y_test, y_test_pred),3)\n",
        "  mape = round((mean_absolute_percentage_error(y_test, y_test_pred)*100),3)\n",
        "\n",
        "  print(f\"\\nLGBM {result_name} Results\")\n",
        "  print(f\"평균 제곱 오차(MSE): {mse}\")\n",
        "  print(f\"평균 절대 오차(MAE): {mae}\")\n",
        "  print(f\"평균 제곱 오차(MSE): {rmse}\")\n",
        "  print(f\"평균 절대비율 오차(MAPE): {mape}\")\n",
        "  print(f\"결정 계수(R2): {r2}\\n\")\n",
        "\n",
        "  result_list = ['mse', 'rmse', 'mae', 'mape', 'r2']\n",
        "  result_name = str(result_name)\n",
        "  result_df = pd.DataFrame(data=[mse, rmse, mae, mape, r2],\n",
        "                           index=result_list, columns=[result_name])\n",
        "  return result_df\n"
      ],
      "metadata": {
        "id": "4HpM_jx23qeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연도 정규화 제외\n",
        "df = full2_data.copy()\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\",\"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ],
      "metadata": {
        "id": "KbIwzejd24Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연도 이상치 1980이하 제거\n",
        "df = full2_data.copy()\n",
        "df = df[df[\"year\"]>1980]\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"year\",\"mileage\", \"tax\", \"mpg\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ],
      "metadata": {
        "id": "jf7Ij4at3HsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# engineSize 정규화 제외\n",
        "df = full2_data.copy()\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"year\" , \"mileage\", \"tax\", \"mpg\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ],
      "metadata": {
        "id": "_wHORiX_3Hp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['fuelType'].unique()"
      ],
      "metadata": {
        "id": "rAGCwJwm3Hno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엔진 사이즈 중 0이며 엔진인경우 제외\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "able_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"year\",\"mileage\", \"tax\", \"mpg\", \"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_base, rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ],
      "metadata": {
        "id": "J9NfhXWF3Hgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엔진 사이즈 이상치, 연도 이상치, 연도 정규화X\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "df = df[df[\"year\"]>1980]\n",
        "able_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\", \"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "log_y_test, log_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_base, rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ],
      "metadata": {
        "id": "u8l3KDXT3RFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna scikit-learn"
      ],
      "metadata": {
        "id": "K8JyuFUk3RDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 데이터 로드\n",
        "df = full2_data.copy()\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "df = df[df[\"year\"]>1980]\n",
        "able_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "# 데이터 스케일링\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\",\"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "\n",
        "\n",
        "# 목적 함수 정의\n",
        "def objective(trial):\n",
        "    # 하이퍼파라미터 범위 설정\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300) # 생성할 트리수\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 20) # 최대 트리 깊이\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20) # 노드 분할 최소 샘플 수\n",
        "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20) # 리프의 최소 샘풀 수\n",
        "\n",
        "    # 모델 생성\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 교차 검증을 통한 평가\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
        "    # MSE가 낮을수록 좋은데 이를 높을 수록 좋은 의미로 변경하기 위해 음수변환을 함.\n",
        "    return np.mean(score)\n",
        "\n",
        "# Optuna 최적화 수행\n",
        "study = optuna.create_study(direction=\"maximize\")  # score 높을 수록 좋은 방향으로 모델로 최적화\n",
        "study.optimize(objective, n_trials=50, n_jobs=-1) # n_trials는 Optuna가 하이퍼파라미터를 탐색하는 총 시도 횟수\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "\n",
        "# 최적 모델 학습 및 평가\n",
        "best_params = study.best_params\n",
        "best_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Test MSE:\", mse)\n",
        "# 'n_estimators': 117, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2"
      ],
      "metadata": {
        "id": "KyW43m_73RA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 모델 학습\n",
        "# 테스트 5개정도 추출해서 예측값과 실제값 확인하기\n",
        "df = full2_data.copy()\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "df = df[df[\"year\"]>1980]\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "n_estimators = 117\n",
        "max_depth = 19\n",
        "min_samples_split = 4\n",
        "min_samples_leaf = 2\n",
        "\n",
        "# 전처리\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "# 데이터 스케일링\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\"] # 표준 정규화할 변수 리스트\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "\n",
        "# 모델 학습\n",
        "model = RandomForestRegressor(n_estimators = 117,\n",
        "                              max_depth = 19,\n",
        "                              min_samples_split = 4,\n",
        "                              min_samples_leaf = 2,\n",
        "                              random_state=42)\n",
        "model.fit(robust_X_train, log_y_train)\n",
        "rfr_feature_importances(model, X_train)\n",
        "train_accuarcy = model.score(robust_X_train, log_y_train)\n",
        "print(\"학습 정확도:\", model.score(robust_X_train, log_y_train))\n",
        "y_test_pred = model.predict(robust_X_test)\n",
        "\n",
        "# 예측 및 개별 트리 예측값 수집\n",
        "tree_predictions = np.array([tree.predict(robust_X_test.to_numpy()) for tree in model.estimators_])\n",
        "\"\"\"랜덤포레스트는 feature name을 사용하지만 결정트리에서는 사용하지 않아 오류발생\n",
        "robust_X_test의 feature name을 제거하기 위해 nupy 배열로 변경\"\"\"\n",
        "tree_predictions = np.expm1(tree_predictions)\n",
        "\n",
        "# 평균 및 신뢰구간 계산\n",
        "y_mean = tree_predictions.mean(axis=0)\n",
        "y_std = tree_predictions.std(axis=0)\n",
        "lower_bound = y_mean - 1.96 * y_std  # 95% 신뢰구간 하한\n",
        "upper_bound = y_mean + 1.96 * y_std  # 95% 신뢰구간 상한\n",
        "\n",
        "\n",
        "# 모델 평가\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "Last_result = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"Last_result\")\n",
        "print(Last_result)\n",
        "\n",
        "# 신뢰구간 그래프 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(trans_y_test)), trans_y_test, color='blue', label=\"Actual\")\n",
        "plt.scatter(range(len(trans_y_test_pred)), trans_y_test_pred, color='red', label=\"Predicted\")\n",
        "plt.fill_between(range(len(trans_y_test_pred)), trans_lower_bound, trans_upper_bound, color='gray', alpha=0.3, label=\"95% CI\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Predicted vs Actual with 95% Confidence Interval\")\n",
        "plt.show()\n",
        "\n",
        "# 테스트 데이터 일부 샘플링\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(len(X_test), size=5, replace=False)\n",
        "X_sample = X_test.iloc[sample_indices]\n",
        "y_sample = y_test.iloc[sample_indices]\n",
        "# 셈플 신뢰구간 구하기\n",
        "tree_predictions = np.array([tree.predict(X_sample.to_numpy()) for tree in model.estimators_])\n",
        "tree_predictions = np.expm1(tree_predictions)\n",
        "y_sample_mean = tree_predictions.mean(axis=0)\n",
        "y_sample_std = tree_predictions.std(axis=0)\n",
        "y_sample_lower_bound = y_sample_mean - 1.96 * y_sample_std\n",
        "y_sample_upper_bound = y_sample_mean + 1.96 * y_sample_std\n",
        "\n",
        "#결과 출력\n",
        "result_df = X_sample.copy()\n",
        "encoding_df=df.copy()\n",
        "le  = LabelEncoder()\n",
        "encoding_df[lable_list] = encoding_df[lable_list].apply(le.fit_transform)\n",
        "result_df[lable_list] = result_df[lable_list].apply(le.inverse_transform)\n",
        "for category in onhot_list:\n",
        "    category_columns = [col for col in result_df.columns if col.startswith(category + \"_\")]\n",
        "    result_df[category] = result_df[category_columns].idxmax(axis=1).str.replace(category + \"_\", \"\")\n",
        "    result_df.drop(columns=category_columns, inplace=True)\n",
        "result_df[\"Actual\"] = y_sample\n",
        "result_df[\"Predicted\"] = y_sample_mean\n",
        "result_df[\"Lower Bound (95%)\"] = y_sample_lower_bound\n",
        "result_df[\"Upper Bound (95%)\"] = y_sample_upper_bound\n",
        "print(result_df)\n",
        "\n",
        "# 결과 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.errorbar(range(5), y_sample_mean,\n",
        "             yerr=1.96 * y_sample_std, fmt='o', label=\"Predicted (95% CI)\", color='red')\n",
        "plt.scatter(range(5), y_sample, color='blue', label=\"Actual\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.title(\"Random Forest Regression: Prediction with 95% Confidence Interval\")\n",
        "plt.show()\n",
        "\n",
        "result_df"
      ],
      "metadata": {
        "id": "EGlN_nv03Q6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}